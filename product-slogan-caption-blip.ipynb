{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0804166f-7088-4987-8893-8f74af685ddb",
   "metadata": {},
   "source": [
    "# Generating marketing slogans for product images\n",
    "\n",
    "This notebook shows how to fine-tune a generative AI model to generate marketing slogans for product images. \n",
    "\n",
    "We start with a foundation model, BLIP, available through HuggingFace. We fine-tune it through an Amazon SageMaker training job. Then we evaluate the generated slogans created by our fine-tuned model to slogans created by an \"out of the box\" model. \n",
    "\n",
    "TL;DR - the fine-tuned model shows better results.\n",
    "\n",
    "| Metric | Baseline model | Fine-tuned model |\n",
    "| -- | -- | -- |\n",
    "| BERT Score (F1 - higher is better) | 0.82 | 0.85 |\n",
    "| WER (lower is better) | 2.06 | 1.24 |\n",
    "| ROUGE (higher is better ) | 0.05 | 0.09 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1b40c",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "    Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "    SPDX-License-Identifier: MIT-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f3780-ccba-4c62-8853-c89ee6d82805",
   "metadata": {},
   "source": [
    "## Data set\n",
    "\n",
    "We use the [Automatic Understanding of Image and Video Advertisements](https://people.cs.pitt.edu/~kovashka/ads/) image dataset. The citation for this data set is:\n",
    "\n",
    "    Automatic Understanding of Image and Video Advertisements. Zaeem Hussain, Mingda Zhang, Xiaozhong Zhang, Keren Ye, Christopher Thomas, Zuha Agha, Nathan Ong, Adriana Kovashka. To appear, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bca719-62b3-4962-863c-7d4c957f0a39",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook was built in Amazon SageMaker Studio. It uses an `ml.g4dn.xlarge` instance with the `PyTorch 1.13 Python 3.9 GPU Optimized` image.\n",
    "\n",
    "Download the data set from the public links. It comes as a set of 11 zip files with images, `subfolder-0.zip` through `subfolder-10.zip`, plus a zip file with metadata, `annotations_images.zip`.\n",
    "\n",
    "Create a directory called `data` in the same directory as this notebook and unzip all of the zip files there. You should end up with one subdirectory for each of the zip files.\n",
    "\n",
    "You will need to make sure that you have increased your default account quotas to let you use a `p4d.24xlarge` instance for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca82163-2899-49b0-8c09-1c5acb407a5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install libraries\n",
    "\n",
    "Make sure we have the latest versions of these packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee0e66-41cf-486a-86ee-0be7cd7dd7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885224a3-c576-475a-bacf-018902c4eb81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80005f4a-b196-496b-8552-af450fe09b31",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "In this section we need to create a dataset in the standard format for images. We need a folder with all of the images, and a metadata file that maps images to ground-truth captions (slogans).\n",
    "\n",
    "We'll read the mapping of slogans to images from the `Slogans.json` file, and update a new metadata list. Since many of the images have muultiple slogans, we will create multiple copies, one for each slogan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c3ecd-9205-442c-84e6-faa74ac19bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/image/Slogans.json', 'r') as S:\n",
    "    slogans = json.load(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745bd26-c68a-4f5e-9d12-b627e98e338b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "image_folder = 'image_folder_blip'\n",
    "\n",
    "if not os.path.exists(image_folder):\n",
    "    os.mkdir(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d4814-9763-4ddd-9871-a445ed7db24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "captions = []\n",
    "for image_file_name in slogans:\n",
    "    path_parts = os.path.split(image_file_name)\n",
    "    base_name = path_parts[-1]\n",
    "    for idx, slogan in enumerate(slogans[image_file_name]):\n",
    "        s_file_name = f\"{idx}-{base_name}\"\n",
    "        captions.append({\"file_name\": s_file_name, \"text\": slogan})\n",
    "        shutil.copyfile(os.path.join('data', image_file_name), os.path.join(image_folder, s_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff5ed6-6230-4ce6-98e8-d8657e3cd5d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(image_folder, \"metadata.jsonl\"), 'w') as f:\n",
    "    for item in captions:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec77ae6-cf89-4f67-a466-29d9e7074a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "ds = load_dataset(\"imagefolder\", data_dir=image_folder, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb741b9-2508-45fa-b0f9-cca63e039211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = ds.train_test_split(test_size=0.1)\n",
    "train_ds = ds[\"train\"]\n",
    "test_ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33334089-23b5-44b1-b7d7-1fac5f752101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "s3_bucket = sess.default_bucket() \n",
    "print(s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ed896-383f-4108-bfdd-0b0511c7d0be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = 'ads/blip/train'\n",
    "test_path = 'ads/blip/test'\n",
    "train_ds.save_to_disk(dataset_path=f\"s3://{s3_bucket}/{train_path}\")\n",
    "test_ds.save_to_disk(dataset_path=f\"s3://{s3_bucket}/{test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc1c690-7f1f-4064-8f18-e19dd167481e",
   "metadata": {},
   "source": [
    "## Run training job\n",
    "\n",
    "Next we'll run a training job on Amazon SageMaker using the HuggingFace classes in the Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bfdbf5-b9ee-4d57-b097-085c5695b599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd77ac7-b5e4-4aa8-9ff0-3b7cebe9fe28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker.huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e88241-29e9-4f8a-8e23-725514540972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={\n",
    "    'epochs': 10,\n",
    "    'model_name': 'Salesforce/blip-image-captioning-base',\n",
    "    'learning_rate': 5e-5,\n",
    "    'train_batch_size': 8,\n",
    "    'output_dir': '/opt/ml/model'\n",
    "}\n",
    "\n",
    "# configuration for running training on smdistributed Data Parallel\n",
    "distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "\n",
    "# instance configurations\n",
    "instance_type='ml.p4d.24xlarge'\n",
    "instance_count=1\n",
    "volume_size=500\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "        entry_point='train.py',\n",
    "        source_dir='./scripts',\n",
    "        instance_type=instance_type,\n",
    "        instance_count=instance_count,\n",
    "        volume_size=volume_size,\n",
    "        role=role,\n",
    "        image_uri='763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:1.13.1-transformers4.26.0-gpu-py39-cu117-ubuntu20.04',\n",
    "        py_version='py39',\n",
    "        distribution= distribution,\n",
    "        hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a1b8c2-9d8f-44c6-9812-43f2bf70817b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.fit(\n",
    "  {'train': f\"s3://{s3_bucket}/{train_path}\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217eb9e-a393-46f0-890c-e8675b0b61c3",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "We'll evaluate the predictions from both the fine-tuned model and the base model against the ground truth slogans. We'll calculate several metrics including WER, BERTScore, and ROUGE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a87b0-2021-4b73-be64-59ec9d2fc5c2",
   "metadata": {},
   "source": [
    "### Download model artifact from S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6002189d-7b0a-4f97-8c3b-181fa09b0e21",
   "metadata": {},
   "source": [
    "In the next cell, specify the job name, which you can find from the output of the `fit` method in the last code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b62ff4-bd63-4a02-8b45-154f3f6c6328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_job_name = 'huggingface-pytorch-training-2023-03-30-01-58-11-853'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fadf78-ccf8-46bb-8060-5217834537a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_artifact = sess.describe_training_job(training_job_name)['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c54635-dc43-4148-a531-bdca5572a63d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_folder = 'model_folder_blip'\n",
    "\n",
    "if not os.path.exists(model_folder):\n",
    "    os.mkdir(model_folder)\n",
    "    \n",
    "sagemaker.s3.S3Downloader.download(model_artifact, model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea72838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar zxf model_folder_blip/model.tar.gz -C model_folder_blip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab554235-fbfd-4297-820b-8e257e0450b2",
   "metadata": {},
   "source": [
    "### Load model and preview results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc85d1e4-dc59-44e8-89c8-370f7bfe1f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BlipForConditionalGeneration\n",
    "model = BlipForConditionalGeneration.from_pretrained(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca768b1-84e1-4f44-b8dc-ef8f3a9aa0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757323b-f643-48ff-9f34-b241bc7c0418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "b_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b9195-131c-4c4b-ba64-2728b7f41e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "fig = plt.figure(figsize=(18, 35))\n",
    "\n",
    "# prepare image for the model\n",
    "for cnt in range(12):\n",
    "    idx = random.randint(0, len(test_ds))\n",
    "    example = test_ds[idx]\n",
    "    image = example[\"image\"]\n",
    "    orig_caption = example[\"text\"]\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    pixel_values = inputs.pixel_values\n",
    "\n",
    "    generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
    "    generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    b_ids = b_model.generate(pixel_values=pixel_values, max_length=50)\n",
    "    b_caption = processor.batch_decode(b_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    fig.add_subplot(6, 2, cnt+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Original: {orig_caption}\\nGenerated: {generated_caption}\\nBaseline: {b_caption}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea0ebe-2608-49de-bc56-f6a0962abe97",
   "metadata": {},
   "source": [
    "### Get predictions from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a70142-f00d-411c-80b0-79c1fa13ec55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add1528-30c5-435a-a672-570d9bbdd7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a642e9b-2a57-4964-a972-7485e07877c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "b_predictions = []\n",
    "references = []\n",
    "\n",
    "for idx in range(len(test_ds)):\n",
    "    example = test_ds[idx]\n",
    "    image = example[\"image\"]\n",
    "    orig_caption = example[\"text\"]\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    pixel_values = inputs.pixel_values\n",
    "\n",
    "    generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
    "    generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    b_ids = b_model.generate(pixel_values=pixel_values, max_length=50)\n",
    "    b_caption = processor.batch_decode(b_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    references.append(orig_caption)\n",
    "    predictions.append(generated_caption)\n",
    "    b_predictions.append(b_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ea716-c1e7-4483-a68d-31407f8c4c9d",
   "metadata": {},
   "source": [
    "### Bert Score (higher is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be698200-62ee-47c5-905d-24f346432526",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "b_results = bertscore.compute(predictions=b_predictions, references=references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e94d41-b9fb-4b60-9c78-55d93e7dd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(f\"F1 - tuned: {np.mean(results['f1'])}, baseline: {np.mean(b_results['f1'])}\")\n",
    "print(f\"Precision - tuned: {np.mean(results['precision'])}, baseline: {np.mean(b_results['precision'])}\")\n",
    "print(f\"Recall - tuned: {np.mean(results['recall'])}, baseline: {np.mean(b_results['recall'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82b24e1-54e8-4236-9d3c-7697898f0c47",
   "metadata": {},
   "source": [
    "### WER (lower is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54cae26-e107-46d1-ae42-157a2fadf236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc28b109-3096-4660-acd3-60f856d4b110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "wer = load(\"wer\")\n",
    "wer_score = wer.compute(predictions=predictions, references=references)\n",
    "b_wer_score = wer.compute(predictions=b_predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9157ac-0299-454a-af1c-9d3f71420cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"WER: {wer_score}, baseline: {b_wer_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53215745-a9e0-498e-9176-e4ebba25a984",
   "metadata": {},
   "source": [
    "### Rouge (higher is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa92e01-8ca4-4d93-a637-5cec7e1e0e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rouge-score nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f2a537-0223-4e71-bbbb-264f038e500f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge = load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f927ddf-f9c8-4138-9cd2-5111fbd6236a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge_result = rouge.compute(predictions=predictions,\n",
    "                             references=references,\n",
    "                             use_aggregator=True)\n",
    "b_rouge_result = rouge.compute(predictions=b_predictions,\n",
    "                             references=references,\n",
    "                             use_aggregator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e1215-fba6-47dc-ada5-6eebbfb9bdf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99b69f-3f8e-42bb-b227-275fdf03f5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b_rouge_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15dae3f-f234-4939-b52d-c4b2efd263d2",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Next steps might include trying different foundation models, training for more epochs, or adding human feedback to improve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77956310-6867-42a3-98b5-4440662d9d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
