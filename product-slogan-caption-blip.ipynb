{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0804166f-7088-4987-8893-8f74af685ddb",
   "metadata": {},
   "source": [
    "# Generating marketing slogans for product images\n",
    "\n",
    "This notebook shows how to fine-tune a generative AI model to generate marketing slogans for product images. \n",
    "\n",
    "We start with a foundation model, BLIP, available through HuggingFace. We fine-tune it through an Amazon SageMaker training job. Then we evaluate the generated slogans created by our fine-tuned model to slogans created by an \"out of the box\" model. \n",
    "\n",
    "TL;DR - the fine-tuned model shows better results.\n",
    "\n",
    "| Metric | Baseline model | Fine-tuned model |\n",
    "| -- | -- | -- |\n",
    "| BERT Score (F1 - higher is better) | 0.82 | 0.85 |\n",
    "| WER (lower is better) | 2.06 | 1.24 |\n",
    "| ROUGE (higher is better ) | 0.05 | 0.09 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1b40c",
   "metadata": {},
   "source": [
    "## License\n",
    "\n",
    "    Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
    "    SPDX-License-Identifier: MIT-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f3780-ccba-4c62-8853-c89ee6d82805",
   "metadata": {},
   "source": [
    "## Data set\n",
    "\n",
    "We use the [Automatic Understanding of Image and Video Advertisements](https://people.cs.pitt.edu/~kovashka/ads/) image dataset. The citation for this data set is:\n",
    "\n",
    "    Automatic Understanding of Image and Video Advertisements. Zaeem Hussain, Mingda Zhang, Xiaozhong Zhang, Keren Ye, Christopher Thomas, Zuha Agha, Nathan Ong, Adriana Kovashka. To appear, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bca719-62b3-4962-863c-7d4c957f0a39",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook was built in Amazon SageMaker Studio. It uses an `ml.g4dn.xlarge` instance with the `PyTorch 1.13 Python 3.9 GPU Optimized` image.\n",
    "\n",
    "You will need to make sure that you have increased your default account quotas to let you use a `p4d.24xlarge` instance for training.\n",
    "\n",
    "\n",
    "First, specify the S3 bucket where you will store your training data and model artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad197c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# YOU MUST CHANGE THIS VALUE\n",
    "# --------------------------\n",
    "\n",
    "model_and_data_artifact_s3_bucket = '<ENTER-BUCKET-NAME-HERE>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db932d2d",
   "metadata": {},
   "source": [
    "Create 2 directories in the same directory as this notebook.\n",
    "\n",
    "The `data-archives` directory will hold our downloaded files, in case we need them again in the future. The `data` directory will hold the actual unpacked dataset and metadata files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ef0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "if not os.path.exists('data-archives'):\n",
    "    os.mkdir('data-archives')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac10a1",
   "metadata": {},
   "source": [
    "The dataset comes as a set of 11 zip files with images, `subfolder-0.zip` through `subfolder-10.zip`. Download these to the `data-archives` folder in case we need them again in the future. Then unpack them into the `data` folder. In the `data` folder you should end up with one subdirectory for each of the zip files, numbered 0 to 10.\n",
    "\n",
    "These files are large, so the process will take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9cdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_root_url = 'https://storage.googleapis.com/ads-dataset/'\n",
    "\n",
    "for idx in range(11):\n",
    "    data_filename = f'subfolder-{idx}.zip'\n",
    "    print(f'downloading: {data_filename}')\n",
    "    os.system(f'wget -O ./data-archives/{data_filename} {download_root_url}{data_filename}')\n",
    "    print(f'unpacking: {data_filename}')\n",
    "    os.system(f'unzip ./data-archives/{data_filename} -d ./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0285447f",
   "metadata": {},
   "source": [
    "Additionally, we need the metadata for the dataset with annotations, available as `annotations_images.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_root_url = 'https://people.cs.pitt.edu/~kovashka/ads/'\n",
    "data_filename = 'annotations_images.zip'\n",
    "\n",
    "print(f'downloading: {data_filename}')\n",
    "os.system(f'wget -O ./data-archives/{data_filename} {download_root_url}{data_filename}')\n",
    "print(f'unpacking: {data_filename}')\n",
    "os.system(f'unzip ./data-archives/{data_filename} -d ./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca82163-2899-49b0-8c09-1c5acb407a5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Install libraries\n",
    "\n",
    "Make sure we have the latest versions of these packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee0e66-41cf-486a-86ee-0be7cd7dd7e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885224a3-c576-475a-bacf-018902c4eb81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80005f4a-b196-496b-8552-af450fe09b31",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "In this section we need to create a dataset in the standard format for images. We need a folder with all of the images, and a metadata file that maps images to ground-truth captions (slogans).\n",
    "\n",
    "We'll read the mapping of slogans to images from the `Slogans.json` file, and update a new metadata list. Since many of the images have muultiple slogans, we will create multiple copies, one for each slogan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9c3ecd-9205-442c-84e6-faa74ac19bcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/image/Slogans.json', 'r') as S:\n",
    "    slogans = json.load(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745bd26-c68a-4f5e-9d12-b627e98e338b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "image_folder = 'image_folder_blip'\n",
    "\n",
    "if not os.path.exists(image_folder):\n",
    "    os.mkdir(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851d4814-9763-4ddd-9871-a445ed7db24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "captions = []\n",
    "for image_file_name in slogans:\n",
    "    path_parts = os.path.split(image_file_name)\n",
    "    base_name = path_parts[-1]\n",
    "    for idx, slogan in enumerate(slogans[image_file_name]):\n",
    "        s_file_name = f\"{idx}-{base_name}\"\n",
    "        captions.append({\"file_name\": s_file_name, \"text\": slogan})\n",
    "        shutil.copyfile(os.path.join('data', image_file_name), os.path.join(image_folder, s_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff5ed6-6230-4ce6-98e8-d8657e3cd5d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(image_folder, \"metadata.jsonl\"), 'w') as f:\n",
    "    for item in captions:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec77ae6-cf89-4f67-a466-29d9e7074a6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset \n",
    "\n",
    "ds = load_dataset(\"imagefolder\", data_dir=image_folder, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb741b9-2508-45fa-b0f9-cca63e039211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = ds.train_test_split(test_size=0.1)\n",
    "train_ds = ds[\"train\"]\n",
    "test_ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33334089-23b5-44b1-b7d7-1fac5f752101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "s3_bucket = sess.default_bucket() \n",
    "print(s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ed896-383f-4108-bfdd-0b0511c7d0be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = 'ads/blip/train'\n",
    "test_path = 'ads/blip/test'\n",
    "train_ds.save_to_disk(dataset_path=f\"s3://{s3_bucket}/{train_path}\")\n",
    "test_ds.save_to_disk(dataset_path=f\"s3://{s3_bucket}/{test_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc1c690-7f1f-4064-8f18-e19dd167481e",
   "metadata": {},
   "source": [
    "## Run training job\n",
    "\n",
    "Next we'll run a training job on Amazon SageMaker using the HuggingFace classes in the Python SDK.\n",
    "\n",
    "Your model artifact `model.tar.gz` will be stored in the SageMaker session's default bucket, which we will assign to the same bucket that we used for the train/test data through the  `model_and_data_artifact_s3_bucket` variable. Models will be stored in this bucket with a prefix corresponding to the generated SageMaker training job name used to create the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cd2e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import sagemaker.huggingface\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=model_and_data_artifact_s3_bucket)\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bba1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={\n",
    "    'epochs': 10,\n",
    "    'model_name': 'Salesforce/blip-image-captioning-base',\n",
    "    'learning_rate': 5e-5,\n",
    "    'train_batch_size': 8,\n",
    "    'output_dir': '/opt/ml/model'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f491c9d8",
   "metadata": {},
   "source": [
    "If you are using a framework and instance type that supports the [SageMaker Distributed Data Parallel](https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-data-parallel-support.html), you can set the `ENABLE_DATA_PARALLELIZATION_SUPPORT` flag to `True` here. This notebook defaults to `False` because the supported instance types are not part of the default AWS account service quotas.\n",
    "\n",
    "Check your service quotas for the selected instance type in your region via the [AWS Service Quotas dashboard](https://console.aws.amazon.com/servicequotas/home) to ensure you can launch the desired training instance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712a8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set ENABLE_DATA_PARALLELIZATION_SUPPORT to true if service quotas have been allotted for training instances and using frameworks that support SageMaker Data Parallelization.\n",
    "ENABLE_DATA_PARALLELIZATION_SUPPORT = False\n",
    "\n",
    "if ENABLE_DATA_PARALLELIZATION_SUPPORT:\n",
    "    # configuration for running training on smdistributed Data Parallel\n",
    "    distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}\n",
    "\n",
    "    # instance configurations\n",
    "    instance_type='ml.p4d.24xlarge'\n",
    "    instance_count=1\n",
    "    volume_size=500\n",
    "else:\n",
    "    # configuration for running standard training\n",
    "    distribution = {}\n",
    "    # instance configurations\n",
    "    instance_type='ml.g5.16xlarge'\n",
    "    instance_count=1\n",
    "    volume_size=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ff8441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric definition to extract the results\n",
    "metric_definitions=[\n",
    "     {'Name': 'train_runtime', 'Regex': \"'train_runtime': (.*?),\"},\n",
    "     {'Name': 'train_samples_per_second', 'Regex': \"'train_samples_per_second': (.*?),\"},\n",
    "     {'Name': 'train_loss', 'Regex': \"'train_loss': (.*?),\"}\n",
    "]\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "        sagemaker_session = sess,\n",
    "        entry_point='train.py',\n",
    "        source_dir='./scripts',\n",
    "        instance_type=instance_type,\n",
    "        instance_count=instance_count,\n",
    "        volume_size=volume_size,\n",
    "        role=role,\n",
    "        image_uri=f'763104351884.dkr.ecr.{region}.amazonaws.com/huggingface-pytorch-training:1.13.1-transformers4.26.0-gpu-py39-cu117-ubuntu20.04',\n",
    "        py_version='py39',\n",
    "        distribution= distribution,\n",
    "        metric_definitions=metric_definitions,\n",
    "        hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a1b8c2-9d8f-44c6-9812-43f2bf70817b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.fit(\n",
    "  {'train': f\"s3://{s3_bucket}/{train_path}\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f4a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'training container used: {huggingface_estimator.image_uri}')\n",
    "print(f'training job name: {huggingface_estimator.latest_training_job.name}')\n",
    "print(f'trained model artifact location: {huggingface_estimator.model_data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7217eb9e-a393-46f0-890c-e8675b0b61c3",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "We'll evaluate the predictions from both the fine-tuned model and the base model against the ground truth slogans. We'll calculate several metrics including WER, BERTScore, and ROUGE.\n",
    "\n",
    "First we will download the trained model artifact from S3 using the estiomator's `model_data` parameter. If you are loading a model artifact that was trained at a different time, set this parameter to the S3 location of the model's `tar.gz` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4450b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_s3_bucket = sess.default_bucket()\n",
    "trained_model_s3_key = f'{huggingface_estimator.latest_training_job.name}/output/model.tar.gz'\n",
    "\n",
    "local_compressed_model_filename = './blip-model-sm.tar.gz'\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(trained_model_s3_bucket).download_file(trained_model_s3_key, local_compressed_model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bd973e",
   "metadata": {},
   "source": [
    "Next, unpack the model artifact for local inference. If you've already unpacked a model in a previous run, rename or delete the folder from a previous run before running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c77b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('blip-model-sm'):\n",
    "    os.mkdir('blip-model-sm')\n",
    "    os.system(f'tar -xvzf {local_compressed_model_filename} -C ./blip-model-sm')\n",
    "else:\n",
    "    print('Did not uncompress model: model artifact may already exist in the target location. Delete or rename the folder and re-run this cell.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab554235-fbfd-4297-820b-8e257e0450b2",
   "metadata": {},
   "source": [
    "### Load model and preview results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc85d1e4-dc59-44e8-89c8-370f7bfe1f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BlipForConditionalGeneration\n",
    "model = BlipForConditionalGeneration.from_pretrained('./blip-model-sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca768b1-84e1-4f44-b8dc-ef8f3a9aa0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757323b-f643-48ff-9f34-b241bc7c0418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "b_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b9195-131c-4c4b-ba64-2728b7f41e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "fig = plt.figure(figsize=(18, 35))\n",
    "\n",
    "# prepare image for the model\n",
    "for cnt in range(12):\n",
    "    idx = random.randint(0, len(test_ds))\n",
    "    example = test_ds[idx]\n",
    "    image = example[\"image\"]\n",
    "    orig_caption = example[\"text\"]\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    pixel_values = inputs.pixel_values\n",
    "\n",
    "    generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
    "    generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    b_ids = b_model.generate(pixel_values=pixel_values, max_length=50)\n",
    "    b_caption = processor.batch_decode(b_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    fig.add_subplot(6, 2, cnt+1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Original: {orig_caption}\\nGenerated: {generated_caption}\\nBaseline: {b_caption}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea0ebe-2608-49de-bc56-f6a0962abe97",
   "metadata": {},
   "source": [
    "### Get predictions from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a70142-f00d-411c-80b0-79c1fa13ec55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add1528-30c5-435a-a672-570d9bbdd7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a642e9b-2a57-4964-a972-7485e07877c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "b_predictions = []\n",
    "references = []\n",
    "\n",
    "for idx in range(len(test_ds)):\n",
    "    example = test_ds[idx]\n",
    "    image = example[\"image\"]\n",
    "    orig_caption = example[\"text\"]\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    pixel_values = inputs.pixel_values\n",
    "\n",
    "    generated_ids = model.generate(pixel_values=pixel_values, max_length=50)\n",
    "    generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    b_ids = b_model.generate(pixel_values=pixel_values, max_length=50)\n",
    "    b_caption = processor.batch_decode(b_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    references.append(orig_caption)\n",
    "    predictions.append(generated_caption)\n",
    "    b_predictions.append(b_caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ea716-c1e7-4483-a68d-31407f8c4c9d",
   "metadata": {},
   "source": [
    "### Bert Score (higher is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be698200-62ee-47c5-905d-24f346432526",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "b_results = bertscore.compute(predictions=b_predictions, references=references, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e94d41-b9fb-4b60-9c78-55d93e7dd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(f\"F1 - tuned: {np.mean(results['f1'])}, baseline: {np.mean(b_results['f1'])}\")\n",
    "print(f\"Precision - tuned: {np.mean(results['precision'])}, baseline: {np.mean(b_results['precision'])}\")\n",
    "print(f\"Recall - tuned: {np.mean(results['recall'])}, baseline: {np.mean(b_results['recall'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82b24e1-54e8-4236-9d3c-7697898f0c47",
   "metadata": {},
   "source": [
    "### WER (lower is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54cae26-e107-46d1-ae42-157a2fadf236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc28b109-3096-4660-acd3-60f856d4b110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "wer = load(\"wer\")\n",
    "wer_score = wer.compute(predictions=predictions, references=references)\n",
    "b_wer_score = wer.compute(predictions=b_predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9157ac-0299-454a-af1c-9d3f71420cd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"WER: {wer_score}, baseline: {b_wer_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53215745-a9e0-498e-9176-e4ebba25a984",
   "metadata": {},
   "source": [
    "### Rouge (higher is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa92e01-8ca4-4d93-a637-5cec7e1e0e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install rouge-score nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f2a537-0223-4e71-bbbb-264f038e500f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge = load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f927ddf-f9c8-4138-9cd2-5111fbd6236a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge_result = rouge.compute(predictions=predictions,\n",
    "                             references=references,\n",
    "                             use_aggregator=True)\n",
    "b_rouge_result = rouge.compute(predictions=b_predictions,\n",
    "                             references=references,\n",
    "                             use_aggregator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e1215-fba6-47dc-ada5-6eebbfb9bdf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rouge_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99b69f-3f8e-42bb-b227-275fdf03f5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b_rouge_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15dae3f-f234-4939-b52d-c4b2efd263d2",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Next steps might include trying different foundation models, training for more epochs, or adding human feedback to improve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77956310-6867-42a3-98b5-4440662d9d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
